{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f62e18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9db089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen=ImageDataGenerator(rescale=1./255)\n",
    "val_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_path=\"/Users/tinagong/Downloads/horse-or-human 2/train\"\n",
    "val_path=\"/Users/tinagong/Downloads/horse-or-human 2/validation\"\n",
    "\n",
    "train_data=train_gen.flow_from_directory(\n",
    "                                        directory=train_path,\n",
    "                                        class_mode=\"binary\",\n",
    "                                        target_size=(300,300),\n",
    "                                        batch_size=6 \n",
    "                                        )\n",
    "\n",
    "val_data=val_gen.flow_from_directory(\n",
    "                                    directory=val_path,\n",
    "                                    class_mode=\"binary\",\n",
    "                                    target_size=(300,300),\n",
    "                                    batch_size=6\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d223ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 298, 298, 3)       84        \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 297, 297, 3)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 264627)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16936192  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,937,333\n",
      "Trainable params: 16,937,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer=Input(shape=(300,300,3))\n",
    "layer=Conv2D(filters=3,kernel_size=(3,3),activation=\"relu\",padding=\"valid\")(input_layer)\n",
    "layer=MaxPool2D(pool_size=(2,2),strides=(1,1))(layer)\n",
    "layer=Flatten()(layer)\n",
    "layer=Dense(64,activation=\"relu\")(layer)\n",
    "layer=Dense(16,activation=\"relu\")(layer)\n",
    "layer=Dropout(0.6)(layer)\n",
    "output_layer=Dense(1,activation=\"sigmoid\")(layer)\n",
    "model=Model(inputs=input_layer,outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2081aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 22s 126ms/step - loss: 0.6689 - accuracy: 0.7303 - val_loss: 0.6267 - val_accuracy: 0.8047\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 21s 122ms/step - loss: 0.1917 - accuracy: 0.9533 - val_loss: 1.1171 - val_accuracy: 0.7969\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 21s 123ms/step - loss: 0.0903 - accuracy: 0.9796 - val_loss: 1.7148 - val_accuracy: 0.7578\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 22s 126ms/step - loss: 0.0623 - accuracy: 0.9854 - val_loss: 2.1808 - val_accuracy: 0.7539\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 22s 128ms/step - loss: 0.0491 - accuracy: 0.9903 - val_loss: 3.1173 - val_accuracy: 0.7656\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 22s 128ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 3.1207 - val_accuracy: 0.7539\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 23s 133ms/step - loss: 0.0496 - accuracy: 0.9883 - val_loss: 2.0176 - val_accuracy: 0.7617\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 23s 135ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 1.8133 - val_accuracy: 0.8047\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 22s 128ms/step - loss: 0.0519 - accuracy: 0.9912 - val_loss: 4.3169 - val_accuracy: 0.7656\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 22s 127ms/step - loss: 0.0411 - accuracy: 0.9922 - val_loss: 4.4667 - val_accuracy: 0.7539\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 23s 132ms/step - loss: 0.0364 - accuracy: 0.9922 - val_loss: 3.9942 - val_accuracy: 0.7539\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 23s 136ms/step - loss: 0.0330 - accuracy: 0.9951 - val_loss: 4.4122 - val_accuracy: 0.7734\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 26s 154ms/step - loss: 0.0234 - accuracy: 0.9961 - val_loss: 5.6058 - val_accuracy: 0.7656\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 24s 140ms/step - loss: 0.0239 - accuracy: 0.9961 - val_loss: 6.1821 - val_accuracy: 0.7656\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 23s 134ms/step - loss: 0.0212 - accuracy: 0.9990 - val_loss: 6.3108 - val_accuracy: 0.7695\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 24s 137ms/step - loss: 0.0285 - accuracy: 0.9932 - val_loss: 4.3285 - val_accuracy: 0.7695\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 24s 137ms/step - loss: 0.0216 - accuracy: 0.9981 - val_loss: 5.6015 - val_accuracy: 0.7773\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 24s 139ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 4.4084 - val_accuracy: 0.7812\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 24s 141ms/step - loss: 0.0239 - accuracy: 0.9971 - val_loss: 5.2857 - val_accuracy: 0.7812\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 25s 148ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 5.6386 - val_accuracy: 0.7852\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",metrics=[\"accuracy\"],optimizer=\"Adam\")\n",
    "history=model.fit(train_data,epochs=20,validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28be3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 32ms/step - loss: 5.6386 - accuracy: 0.7852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.638579368591309, 0.78515625]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f2e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
